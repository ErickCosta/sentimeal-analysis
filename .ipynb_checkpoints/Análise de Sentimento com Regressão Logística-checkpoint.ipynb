{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Sentimento com Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este guia trás um exemplo de como usar o SHAP em conjunto com um modelo baseado em regressão logística para análise de sentimentos. O conjunto de dados utilziado é o IMDB. O grande destaque deste guia é perceber que palavras inexistentes nos textos são tão importantes quanto as existentes.\n",
    "\n",
    "Este guia é uma tradução livre do material disponibilizado por Scott Lundberg (todos os direitos reservados ao autor) em:\n",
    "\n",
    "https://slundberg.github.io/shap/notebooks/linear_explainer/Sentiment%20Analysis%20with%20Logistic%20Regression.html\n",
    "\n",
    "O objetivo aqui é disponibilziar material de grande relevância para impulsinar o ecosistema da temática abordada em língua portuguesa (PT-BR).\n",
    "\n",
    "Bons estudos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando as Dependências do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o Conjunto de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante a concepção deste projeto, o código inicial proposto não conseguiu carregar os dados direto da base do IMDB (por um erro de codificação), logo, apresentamos abaixo duas possibilidades para solucionar o problema:\n",
    "\n",
    "- 1º solução para o problema de importação dos dados: Localize o conjunto de dados do IMDB que pode ser encontrado na pasta onde o shap foi instalado via PIP ou gerenciador de pacotes, basta acessar os packages de libs externas, o conteúdo do arquivo estará dentro da pasta \"cached_data\". Após ocalizar o arquivo, realize um paste na pasta \"dataset\" na raiz deste projeto.\n",
    "\n",
    "\n",
    "- 2º solução para o problema de importação dos dados: Outra forma de corrigir a importação é abrindo o arquivo \"datasets\" na raiz da instalação do SHAP via PIP ou gerenciador de pacotes e modifocando a linha 54 para:\n",
    "\n",
    "    \"with open(cache(github_data_url + \"imdb_train.txt\"), encoding=\"utf8\") as f:\"\n",
    "\n",
    "As duas propostas tem como objetivo usar a codificação correta para importação dos dados. Caso contrário, o erro irpa persistir até os responsáveis pelo SHAP realizarem a correção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se optou pela primeira opção de correção opção execute o trecho abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb():\n",
    "    with open(\"dataset\\\\imdb_train.txt\", encoding=\"utf8\") as f:\n",
    "        data = f.readlines()\n",
    "    y = np.ones(25000, dtype=np.bool)\n",
    "    y[:12500] = 0\n",
    "    return data, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus,y = imdb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se optou pela segunda opção de correção execute o trecho abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus,y = shap.datasets.imdb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo Amostras de Treinamento e Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train, corpus_test, y_train, y_test = train_test_split(corpus, y, test_size=0.2, random_state=7)\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=10)\n",
    "X_train = vectorizer.fit_transform(corpus_train)\n",
    "X_test = vectorizer.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando um Modelo de Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.linear_model.LogisticRegression(penalty=\"l1\", C=0.1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicando o Modelo Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construindo o explicador SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(model, X_train, feature_dependence=\"independent\")\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "X_test_array = X_test.toarray() # we need to pass a dense version for the plotting functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sumarizando o efeito das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test_array, feature_names=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao obervar o gráfico acima, percebemos que as features mais relevantes para revisões de filmes positivas e negativas estão bem aparentes. Notemos que, para predições positivas, as features mais significativas apresentam picos em vermelho com valores acima de zero no eixo X. De forma inversa, as features significativas para predições negativas, apresentam picos em vermelho com valores abaixo de zero no eixo X. Destacamos ainda que, para predições positivas, de acordo com os valores apresentados pelo SHAP, o termo \"bad\" é o maior característico para aumentar a probabilidade de um review ser classificado como negativo. No que diz respeito ao termo característico para reviews positivos, considerando as informações apresentadas no gráfico, podemos obervar o termo \"great\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicando a primeira revisão do conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "print(\"Positive\" if y_test[ind] else \"Negative\", \"Review:\")\n",
    "print(corpus_test[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(\n",
    "    explainer.expected_value, shap_values[ind,:], X_test_array[ind,:],\n",
    "    feature_names=vectorizer.get_feature_names()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao observar a influência das features no primeiro review, podemos identificar as features que \"empurraram\" a classificação para uma possível positividade (\"and\", \"it\", \"best\", \"great\"). Além disso, percebemos também que, embora o review possa tender a positividade, existem features que tentaram e influenciar um review negativo (\"even\", \"to\"). É necessário destacar que os dados podem ser refinados para que ele possa utilizar features com menos ruídos: descartando stopwords, por exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicando a segunda revisão do conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 1\n",
    "print(\"Positive\" if y_test[ind] else \"Negative\", \"Review:\")\n",
    "print(corpus_test[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(\n",
    "    explainer.expected_value, shap_values[ind,:], X_test_array[ind,:],\n",
    "    feature_names=vectorizer.get_feature_names()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso, podemos obervar um comportamento contrário ao do primeiro review. Claramente, percebemos que as features que tendem a caracterizar um review negativo estão mais presentes e elevam a probabilidade de uma revisão negativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
